{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDmgsG8Hhu3m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
        "\n",
        "# Read and process dataset\n",
        "papers = pd.read_csv(\"datasets/papers.csv\")\n",
        "papers.drop(['id', 'event_type', 'pdf_name'], axis=1, inplace=True)\n",
        "\n",
        "# Bar plot for publications per year\n",
        "counts = papers.groupby('year').size()\n",
        "counts.plot(kind='bar', title=\"ML Publications (1987â€“2017)\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.show()\n",
        "\n",
        "# Process titles: clean text\n",
        "papers['title_processed'] = papers['title'].str.replace('[,\\.!?]', '', regex=True).str.lower()\n",
        "\n",
        "# Word Cloud\n",
        "wc = WordCloud()\n",
        "wc.generate(' '.join(papers['title_processed']))\n",
        "wc.to_image().show()\n",
        "\n",
        "# Common Words\n",
        "def plot_top_words(data, vectorizer):\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "    total_counts = np.array(data.sum(axis=0)).flatten()\n",
        "    top_words = sorted(zip(words, total_counts), key=lambda x: -x[1])[:10]\n",
        "\n",
        "    plt.bar(*zip(*top_words))\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title('10 Most Common Words')\n",
        "    plt.show()\n",
        "\n",
        "count_vec = CountVectorizer(stop_words='english')\n",
        "count_data = count_vec.fit_transform(papers['title_processed'])\n",
        "plot_top_words(count_data, count_vec)\n",
        "\n",
        "# LDA Topics\n",
        "def print_topics(lda_model, vectorizer, n_words=10):\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "    for i, topic in enumerate(lda_model.components_):\n",
        "        print(f\"\\nTopic {i}: \" + \" \".join([words[j] for j in topic.argsort()[-n_words:][::-1]]))\n",
        "\n",
        "lda = LDA(n_components=10)\n",
        "lda.fit(count_data)\n",
        "\n",
        "print(\"LDA Topics:\")\n",
        "print_topics(lda, count_vec)\n"
      ]
    }
  ]
}